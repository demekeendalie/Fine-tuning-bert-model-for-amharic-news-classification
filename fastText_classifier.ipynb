{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demekeendalie/Fine-tuning-bert-model-for-amharic-news-classification/blob/main/fastText_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "342ICL9sDKR3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80KDeDUdDy4z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J0Xws6fDvmo"
      },
      "outputs": [],
      "source": [
        "# reading the dataset from my drive using the above drive\n",
        "dataframe =pd.read_excel('/content/drive/My Drive/output.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jGASGUyEDNz"
      },
      "outputs": [],
      "source": [
        "# reading the second dataset from the drive\n",
        "dataframe2=pd.read_excel('/content/drive/My Drive/newdata.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLbBP9TqEQET"
      },
      "outputs": [],
      "source": [
        "# merging the two dataframes\n",
        "frame=[dataframe,dataframe2]\n",
        "merge=pd.concat(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAVJsDoEEYJQ"
      },
      "outputs": [],
      "source": [
        "# changing category to numeric\n",
        "label=pd.Categorical(merge['category']).codes\n",
        "label=pd.DataFrame(label)\n",
        "merge['labels']=pd.DataFrame(label)\n",
        "print(merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZSr4Q-MEjI4"
      },
      "outputs": [],
      "source": [
        "del merge['category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QB8Cbv9EqEK"
      },
      "outputs": [],
      "source": [
        "# sheffule the merged dataset\n",
        "dataframe=merge.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97MHtaEe36Ja"
      },
      "outputs": [],
      "source": [
        "#normalizarion\n",
        "import re\n",
        "#method to normalize character level missmatch such as ጸሀይ and ፀሐይ\n",
        "def normalization(input_token):\n",
        "    rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
        "    rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
        "    rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
        "    rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
        "    rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
        "    rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
        "    rep7=re.sub('[ሠ]','ሰ',rep6)\n",
        "    rep8=re.sub('[ሡ]','ሱ',rep7)\n",
        "    rep9=re.sub('[ሢ]','ሲ',rep8)\n",
        "    rep10=re.sub('[ሣ]','ሳ',rep9)\n",
        "    rep11=re.sub('[ሤ]','ሴ',rep10)\n",
        "    rep12=re.sub('[ሥ]','ስ',rep11)\n",
        "    rep13=re.sub('[ሦ]','ሶ',rep12)\n",
        "    rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
        "    rep15=re.sub('[ዑ]','ኡ',rep14)\n",
        "    rep16=re.sub('[ዒ]','ኢ',rep15)\n",
        "    rep17=re.sub('[ዔ]','ኤ',rep16)\n",
        "    rep18=re.sub('[ዕ]','እ',rep17)\n",
        "    rep19=re.sub('[ዖ]','ኦ',rep18)\n",
        "    rep20=re.sub('[ጸ]','ፀ',rep19)\n",
        "    rep21=re.sub('[ጹ]','ፁ',rep20)\n",
        "    rep22=re.sub('[ጺ]','ፂ',rep21)\n",
        "    rep23=re.sub('[ጻ]','ፃ',rep22)\n",
        "    rep24=re.sub('[ጼ]','ፄ',rep23)\n",
        "    rep25=re.sub('[ጽ]','ፅ',rep24)\n",
        "    rep26=re.sub('[ጾ]','ፆ',rep25)\n",
        "    rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
        "    rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
        "    rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
        "    rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
        "    rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
        "    rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
        "    rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
        "    rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
        "    rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
        "    rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
        "    rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
        "    rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
        "    rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
        "    rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
        "    rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
        "    rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
        "    rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
        "    rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
        "    rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
        "    rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
        "    rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
        "    rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ\n",
        "    return rep48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DplY7I_y3zUd"
      },
      "outputs": [],
      "source": [
        "# apply normalization and special characters removal\n",
        "dataframe['articles']=dataframe['articles'].apply(lambda x: normalization(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQDjonh33tnL"
      },
      "outputs": [],
      "source": [
        "# special symbol removal\n",
        "dataframe['articles']=dataframe['articles'].str.replace('[^\\w\\s]','',regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QYuRpSItMzV"
      },
      "outputs": [],
      "source": [
        "# removing digits from the dataset\n",
        "dataframe['articles']=dataframe['articles'].str.replace('\\d+','',regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MsG8sbn6kNz"
      },
      "outputs": [],
      "source": [
        "# drawing density graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k79DG0bui2S"
      },
      "outputs": [],
      "source": [
        "#formating the dataset to the fasttext format __label___ data\n",
        "dataframe['formatted']=\"__label__\"+dataframe['labels'].astype(str)+\" \"+dataframe['articles']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1u_dmTd5sPk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJHYRChx55B5"
      },
      "outputs": [],
      "source": [
        "dataframe.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCvQZEmcwn2N"
      },
      "outputs": [],
      "source": [
        "# train test spliting and taking only the formated column\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test=train_test_split(dataframe['formatted'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RGTNW-x6SEx"
      },
      "outputs": [],
      "source": [
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8C-eVLwxY0w"
      },
      "outputs": [],
      "source": [
        "# save the training and testing data\n",
        "train.to_csv(\"news.train\",header=False,index=False)\n",
        "test.to_csv(\"news.test\",header=False,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p4lj2wyzyknM",
        "outputId": "50ac6e76-cbd4-4da2-ad97-e33494b22182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199773 sha256=d5b93b5effef8f2a6b74cb91480f155956237570ef6c60d9fb7751951441e7e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ic_u3YpvzISw"
      },
      "outputs": [],
      "source": [
        "import fasttext as ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAylqZVHzPld"
      },
      "outputs": [],
      "source": [
        "# training the model\n",
        "model=ft.train_supervised(input=\"news.train\",loss='softmax',epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WAxzaoEzhga"
      },
      "outputs": [],
      "source": [
        "# testing the model\n",
        "predict=model.test(\"news.test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVhDROzSuvts"
      },
      "outputs": [],
      "source": [
        "print(predict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfDqe8PodFhVDOOcdAr2UT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}