{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfbQmNi5GT2iWZIwQntt3V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demekeendalie/Fine-tuning-bert-model-for-amharic-news-classification/blob/main/Bag_of_word_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "OhJdh97irjX1"
      },
      "outputs": [],
      "source": [
        "#importing basic packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5yBut3OtALq",
        "outputId": "306a2475-cbf8-4a28-90c8-60e00ca3346c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the dataset from my drive using the above drive\n",
        "dataframe1 =pd.read_excel('/content/drive/My Drive/dataset1.xlsx')\n",
        "dataframe2 =pd.read_excel('/content/drive/My Drive/dataset2.xlsx')"
      ],
      "metadata": {
        "id": "Atnu7KLrtSev"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging the two dataframes\n",
        "frame=[dataframe1,dataframe2]\n",
        "dataframe=pd.concat(frame)"
      ],
      "metadata": {
        "id": "TExn7JejtfDj"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci03g7OItk8m",
        "outputId": "19f744ff-ca20-4d92-bd76-93b0a92ba76b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              articles   category\n",
            "0     ግንቦት 13/2011  በተሽከርካሪ አደጋ ድንገተኛ ህክምና የተፈቀደው ሁ...   accident\n",
            "1    ሚያዝያ  25/ 2011 የሰሜን ተራሮች ብሄራዊ ፓርክን የአደጋ ስጋቶች ለ...   accident\n",
            "2    በደቡብ ወሎ ዞን ኩታበር ወረዳ ዛሬ በደረሰ የትራፊክ አደጋ በ11 ሰዎች ...   accident\n",
            "3    የህዝብ ተወካዮች ምክር ቤት አባላት ዛሬ ጠዋት የተፈናቀሉ ወገኖችን ለመጎ...   accident\n",
            "4    በባህር ዳር ከተማ ቀበሌ 05 በእሳት አደጋ ቤትና ንብረት የወደመባቸው ሰ...   accident\n",
            "..                                                 ...        ...\n",
            "695  ጎባ፤ መስከረም 16/2015 (ኢዜአ) መደ ወላቡ ዩኒቨርሲቲ ተጨማሪ 13 ...  education\n",
            "696  ባህር ዳር ሰኔ 7/2010 በአማራ ክልል ከህብረተሰቡ ከደረሱት ጥቆማዎች ...  education\n",
            "697  አዲስ አበባ ሰኔ 29/2010 የትምህርት ጥራት ጉድለት በአገሪቱ ላይ ዘር...  education\n",
            "698  አዲስ አበባ፤ መስከረም 15/ 2016 (ኢዜአ)፦ በተባበሩት አረብ ኤምሬቶ...  education\n",
            "699  አዲስ አበባ መጋቢት 4/2012(ኢዜአ) ግማሽ ቢሊዮን ብር ወጪ የተደረገበ...  education\n",
            "\n",
            "[2181 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing category to numeric\n",
        "label=pd.Categorical(dataframe['category']).codes\n",
        "label=pd.DataFrame(label)\n",
        "dataframe['labels']=pd.DataFrame(label)\n",
        "print(dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEcryp9GtvPA",
        "outputId": "f871afe6-30f7-4c79-86c2-ce0caf0a2794"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              articles   category  labels\n",
            "0     ግንቦት 13/2011  በተሽከርካሪ አደጋ ድንገተኛ ህክምና የተፈቀደው ሁ...   accident       0\n",
            "1    ሚያዝያ  25/ 2011 የሰሜን ተራሮች ብሄራዊ ፓርክን የአደጋ ስጋቶች ለ...   accident       0\n",
            "2    በደቡብ ወሎ ዞን ኩታበር ወረዳ ዛሬ በደረሰ የትራፊክ አደጋ በ11 ሰዎች ...   accident       0\n",
            "3    የህዝብ ተወካዮች ምክር ቤት አባላት ዛሬ ጠዋት የተፈናቀሉ ወገኖችን ለመጎ...   accident       0\n",
            "4    በባህር ዳር ከተማ ቀበሌ 05 በእሳት አደጋ ቤትና ንብረት የወደመባቸው ሰ...   accident       0\n",
            "..                                                 ...        ...     ...\n",
            "695  ጎባ፤ መስከረም 16/2015 (ኢዜአ) መደ ወላቡ ዩኒቨርሲቲ ተጨማሪ 13 ...  education       3\n",
            "696  ባህር ዳር ሰኔ 7/2010 በአማራ ክልል ከህብረተሰቡ ከደረሱት ጥቆማዎች ...  education       3\n",
            "697  አዲስ አበባ ሰኔ 29/2010 የትምህርት ጥራት ጉድለት በአገሪቱ ላይ ዘር...  education       3\n",
            "698  አዲስ አበባ፤ መስከረም 15/ 2016 (ኢዜአ)፦ በተባበሩት አረብ ኤምሬቶ...  education       3\n",
            "699  አዲስ አበባ መጋቢት 4/2012(ኢዜአ) ግማሽ ቢሊዮን ብር ወጪ የተደረገበ...  education       3\n",
            "\n",
            "[2181 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mixing each categories and thier labels\n",
        "dataframe=dataframe.sample(frac=1)"
      ],
      "metadata": {
        "id": "PY9fJaVPt_Qc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['word_len'] = dataframe['articles'].str.split().str.len()\n",
        "print(dataframe['word_len'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dddrQtXVuEd7",
        "outputId": "905b250c-6bbb-4a06-90d4-87d8109a20ae"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314.2563044475011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizarion\n",
        "import re\n",
        "#method to normalize character level missmatch such as ጸሀይ and ፀሐይ\n",
        "def normalization(input_token):\n",
        "    rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
        "    rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
        "    rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
        "    rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
        "    rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
        "    rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
        "    rep7=re.sub('[ሠ]','ሰ',rep6)\n",
        "    rep8=re.sub('[ሡ]','ሱ',rep7)\n",
        "    rep9=re.sub('[ሢ]','ሲ',rep8)\n",
        "    rep10=re.sub('[ሣ]','ሳ',rep9)\n",
        "    rep11=re.sub('[ሤ]','ሴ',rep10)\n",
        "    rep12=re.sub('[ሥ]','ስ',rep11)\n",
        "    rep13=re.sub('[ሦ]','ሶ',rep12)\n",
        "    rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
        "    rep15=re.sub('[ዑ]','ኡ',rep14)\n",
        "    rep16=re.sub('[ዒ]','ኢ',rep15)\n",
        "    rep17=re.sub('[ዔ]','ኤ',rep16)\n",
        "    rep18=re.sub('[ዕ]','እ',rep17)\n",
        "    rep19=re.sub('[ዖ]','ኦ',rep18)\n",
        "    rep20=re.sub('[ጸ]','ፀ',rep19)\n",
        "    rep21=re.sub('[ጹ]','ፁ',rep20)\n",
        "    rep22=re.sub('[ጺ]','ፂ',rep21)\n",
        "    rep23=re.sub('[ጻ]','ፃ',rep22)\n",
        "    rep24=re.sub('[ጼ]','ፄ',rep23)\n",
        "    rep25=re.sub('[ጽ]','ፅ',rep24)\n",
        "    rep26=re.sub('[ጾ]','ፆ',rep25)\n",
        "    rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
        "    rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
        "    rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
        "    rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
        "    rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
        "    rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
        "    rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
        "    rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
        "    rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
        "    rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
        "    rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
        "    rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
        "    rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
        "    rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
        "    rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
        "    rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
        "    rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
        "    rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
        "    rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
        "    rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
        "    rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
        "    rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ\n",
        "    return rep48"
      ],
      "metadata": {
        "id": "BiZInvEfuHro"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply normalization and special characters removal\n",
        "dataframe['articles']=dataframe['articles'].apply(lambda x: normalization(x))"
      ],
      "metadata": {
        "id": "1vDVwnYIuOXR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# special symbol removal\n",
        "dataframe['articles']=dataframe['articles'].str.replace('[^\\w\\s]','',regex=True)"
      ],
      "metadata": {
        "id": "bC-nRDvvubvx"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing digits from the dataset\n",
        "dataframe['articles']=dataframe['articles'].str.replace('\\d+','',regex=True)"
      ],
      "metadata": {
        "id": "RA2Rf2V8ueHz"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe=dataframe[['articles','labels']]"
      ],
      "metadata": {
        "id": "KPPhtoYlyJoP"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train,y_test = train_test_split(dataframe['articles'],dataframe['labels'], test_size=0.20, random_state=42)\n"
      ],
      "metadata": {
        "id": "4it24JWyu3Ht"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "# Create a Bag-of-Words   model\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# create mlp classifier\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100,),activation='relu', solver='adam', max_iter=1000)\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro')) # Changed line: Added average='macro'\n",
        "print(\"Recall:\", recall_score(y_test, y_pred,average='macro')) # Changed line: Added average='macro'\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred,average='macro')) # Changed line: Added average='macro'\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeBQghW-u93d",
        "outputId": "d385adef-8953-482c-8e2e-7b51442e8ef6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.816933638443936\n",
            "Precision: 0.8239332973695637\n",
            "Recall: 0.8261079101850827\n",
            "F1-score: 0.8229460075637317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80        70\n",
            "           1       0.72      0.75      0.73        83\n",
            "           2       0.79      0.66      0.72        50\n",
            "           3       0.81      0.94      0.87        50\n",
            "           4       0.88      0.79      0.83        86\n",
            "           5       0.87      0.91      0.89        44\n",
            "           6       0.92      0.91      0.92        54\n",
            "\n",
            "    accuracy                           0.82       437\n",
            "   macro avg       0.82      0.83      0.82       437\n",
            "weighted avg       0.82      0.82      0.82       437\n",
            "\n"
          ]
        }
      ]
    }
  ]
}