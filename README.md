This project demonstrates how to fine-tune a pretrained BERT model contained in huggingface "Davlan/bert-base-multilingual-cased-finetuned-amharic" for multilabel Amharic news document categorization.
The project's goal is to categorize Amharic news into seven major categories: accidents, sports, agriculture, economics/business, education, health, and politics.
